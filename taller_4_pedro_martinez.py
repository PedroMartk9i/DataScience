# -*- coding: utf-8 -*-
"""Taller #4 Pedro Martinez

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16fGCNYv0DQbd1qB_G4eE5LrMuFxzrmi-
"""

import pandas as pd
import numpy as np
import seaborn as sb
import matplotlib.pyplot as plt
from matplotlib import colors
from scipy.stats import pearsonr, zscore

import statsmodels.api as sm
import statsmodels.formula.api as smf

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error, r2_score
from sklearn import linear_model

#Datos de propiedades
ruta = 'https://raw.githubusercontent.com/rasief/cartografia/master/melb_data.csv'
df = pd.read_csv(ruta)
df

df.dtypes

df = df.select_dtypes(exclude=['object'])
df

#Buscar nulos
df.isnull().sum()

#Borrado de datos nulos
df = df.dropna()
df

#Histograma
df.Price.hist(color='firebrick', bins=100, figsize=(10, 6))

#Diagrama de distribución
fig, ax = plt.subplots(figsize=(10, 6))
df.plot(x = 'BuildingArea', y = 'Price', c = 'navy', kind = "scatter", ax = ax)
ax.set_title('Distribución de precio y area construida');

#Datos con área menor o igual a 800
df0 = df[df["BuildingArea"]<=800]
df0

#Diagrama de distribución
fig, ax = plt.subplots(figsize=(10, 6))
df0.plot(x = 'BuildingArea', y = 'Price', c = 'navy', kind = "scatter", ax = ax)
ax.set_title('Distribución de precio y area construida');

#Datos con área cero
dfzero = df0[df0["BuildingArea"]<5]
len(dfzero)

#Se eliminan los registros de menos de 15 mts cuadrados de area
df0 = df0[df0["BuildingArea"]>=5]
df0

#Se eliminan todos los datos que estén más allá de 3 desviaciones estándar
df0 = df0[(np.abs(zscore(df0['BuildingArea']))<=3)]
df0

#Boxplot
ax = sb.boxplot(data=df0['BuildingArea'].values, orient='h', color='yellow')
ax.set_title('Boxplot area construida');
plt.show()

#Múltiples diagramas por parejas
#sb.set_theme(style="ticks")
#sb.pairplot(df0, hue='Rooms')

#Correlación entre variables
corr_test = pearsonr(x = df['BuildingArea'], y = df['Price'])
print("Coeficiente de correlación de Pearson: ", corr_test[0])
print("P-value: ", corr_test[1])

colormap = plt.cm.viridis
plt.figure(figsize=(10, 10))
plt.title('Pearson Correlation of Features', y=1.05, size=15)
sb.heatmap(df.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)

sb.set_theme(color_codes=True)
sb.set_theme(style="ticks")
ax = sb.regplot(x="BuildingArea", y="Price", data=df0, marker='+', x_jitter=0.2, y_jitter=0.2)
ax.set_title('Distribución de precio y area construida')

#sb.pairplot(df0, kind='reg')

#Regresión lineal (Area construida vs. Precio)
x = df0["BuildingArea"]
y = df0["Price"]
x2 = sm.add_constant(x)
est = sm.OLS(y, x2)
est2 = est.fit()
print(est2.summary())

df0.dtypes

#Regresión lineal múltiple
x = df0.iloc[:,[0,5,8]]
y = df0["Price"]
x2 = sm.add_constant(x)
est = sm.OLS(y, x2)
est2 = est.fit()
print(est2.summary())

df0.drop(columns={'Bedroom2', 'Postcode', 'Lattitude', 'Longtitude'}, inplace=True)
df0

#Regresión lineal múltiple
x = df0.iloc[:,[2,6,7]]
y = df0["Price"]
x2 = sm.add_constant(x)
est = sm.OLS(y, x2)
est2 = est.fit()
print(est2.summary())

#Predicciones con scikit-learn
train, test = train_test_split(df0, test_size = 0.20)
print("Ejemplos usados para entrenar: ", len(train))
print("Ejemplos usados para test: ", len(test))

#Regresión lineal múltiple
x = train.iloc[:,[2,6,7]]
y = train["Price"]
x2 = sm.add_constant(x)
est = sm.OLS(y, x2)
est2 = est.fit()
print(est2.summary())

#Se definen las variables
x_train = train.iloc[:,[2,6,7]]
y_train = train.Price
x_test = test.iloc[:,[2,6,7]]
y_test = test.Price

#Entrenamiento del modelo
regr = LinearRegression()
regr.fit(x_train, y_train)

y_train

#Predicción
y_pred = regr.predict(x_train)
y_pred

print('Coeficientes:\n', regr.coef_)
print('Intercepto eje Y (b):', regr.intercept_)
print("Error cuadrático medio (Mean squared error): %.2f" % mean_squared_error(y_true=y_train, y_pred=y_pred, squared=False))
print('Coef determinación (r^2): %.2f' % r2_score(y_train, y_pred))

for y, y_p in list(zip(y_train, y_pred)) [:10]:
    print("Valor real: {:.2f} - Valor estimado: {:.2f}".format(y, y_p))

predicciones = regr.predict(X=x_test)
print(predicciones[0:10,])
rmse = mean_squared_error(y_true=y_test, y_pred=predicciones, squared=False)
print(f"\nEl error (rmse) del test es: {rmse}")

# Se calcula el coeficiente de determinación
actual = y_test.values.tolist()
predict = predicciones.tolist()

corr_matrix = np.corrcoef(actual, predict)
corr = corr_matrix[0,1]
R_sq = corr**2
R_sq

y_trainArray = np.array(y_train)
y_pred = regr.predict(x_train)
y_predArray = np.array(y_pred)

print("1. El Tipo es: ", type(y_trainArray))
print("2. El tipo es: ", type (y_predArray))

coefficient_of_dermination = r2_score(y_trainArray, y_predArray)


print("Coeficiente de Determinación: ", coefficient_of_dermination)
print("Redondeado: ", round(coefficient_of_dermination,2))


plt.rcParams["figure.figsize"]=[10.00,5.00]
plt.rcParams ["figure.autolayout"] = True
fig, ax1 = plt.subplots()
ax1.plot (y_trainArray, color='Green')
ax2 = ax1. twinx()
ax2.plot (y_predArray, color='Blue')
fig.tight_layout()
plt. show()